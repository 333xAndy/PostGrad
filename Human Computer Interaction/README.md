# Hum-Comp Interaction

## Enactive and Interactive dimensions
### Abstract
   This repo presents artifical agents with behavioral ontogeny based on interactive memorization. That is to say, agents will remember from experience if said    experience proves itself useful later on. Agents will be using continuous times recurrent neural networks (CTRNNs). Upon completion, agents will be able to      adopt new sensorimotor invarients with little guidance from their environment.
   
## Built with
   [![Scala Badge](https://img.shields.io/badge/Scala-DC322F?style=for-the-badge&logo=scala&logoColor=white)](https://www.scala-lang.org/)
   [![VS-Code Badge](https://img.shields.io/badge/VSCode-0078D4?style=for-the-badge&logo=visual%20studio%20code&logoColor=white)](https//code.visualstudio.com/)
   <!--More as you go along-->
   
## Keywords
   Embodied Agent - CTRNN - Memory - Enaction
   
## Author's Thoughts
   In recent times, AI has become somewhat of a superfluous tool and recently over taken the main stream with ways of generating quick cash flows. 
    When people say AI, they often mean machine learning but this further obscures the potential to both and makes them appear more omni-present than not. 
    This approach might lend itself useful to areas of ubiquitous computing. For example, little computers with machine learning tools in everyday objects
    with the population unaware of their inahitance. Still, in order to get to that point in time, we have to take a few steps back and think of a more
    embodied approach.
    
## Introduction
   We open with a question, is cognition truly seamless? Embodied cognitive sciences will tell us enviromental properties are more important than representation of said enviroment. This implies that there exists an incremental trajectory between learning, memory and catergorization coupled with the dynamic interactions. Entire models can be built with this idea alone where the only importance is that of the internal representation without external influence. For example...

<!--Find an example of this alone, one example used is agents showing preference when presentented with two stimuli-->
